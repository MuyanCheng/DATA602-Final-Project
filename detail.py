# -*- coding: utf-8 -*-
"""detail.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1byK7CI5gdGI1agqqRzw24bH5oMwuDorg
"""

#-----General------#
import numpy as np
import pandas as pd
import os
import sys
import math
import random
import string
#-----Plotting-----#
import matplotlib.pyplot as plt
import plotly.graph_objects as go
import plotly.express as px
import plotly.offline as py
py.init_notebook_mode(connected=True)
import seaborn as sns
# from pandas_profiling import ProfileReport

#-----Utility-----#
import itertools
import warnings
warnings.filterwarnings("ignore")
import re
import gc
from bs4 import BeautifulSoup as soup
from urllib.request import Request, urlopen
from datetime import date, datetime
LOOK_AT = 5 # Controls how many bars the user can see in the bar graph
AT_LEAST = 50 # Controls what rank a country must be in terms of total cases to be shown on the bar graph

def get_detail(id, li):
  temp = []
  url = ('https://www.cars.com/vehicledetail/'+str(id))
  req = Request(url)
  webpage_top_50 = urlopen(req)
  page_soup = soup(webpage_top_50, "lxml")
  new_used = page_soup.find("p",{"class":"new-used"})
  if new_used != None:
    temp.append(new_used.text)      #new/used
  else:
    temp.append('')
  title = page_soup.find("h1",{"class":"listing-title"})
  if title != None:
    temp.append(title.text)         #name(title)
  else:
    temp.append('')
  #print(title.text)
  mile = page_soup.find("div",{"class":"listing-mileage"})
  if mile != None:
    temp.append(mile.text)          #mileage
  else:
    temp.append('')
  #print(mile.text)
  price = page_soup.find("span",{"class":"primary-price"})
  if price != None:
    temp.append(price.text)         #price
  else:
    temp.append('')
  temp.append(id)
  #print(price.text)
  info = page_soup.findAll("dl",{"class":"fancy-description-list"})
  if len(info) == 0:
    temp.append('')
    temp.append('')
    temp.append('')
    temp.append('')
    temp.append('')
    temp.append('')
    temp.append('')
    temp.append('')
  elif len(info) == 3 or len(info)==4:
    basic = info[0].findAll("dd")
    #print("basic formed")
    if len(basic) == 10:
      #print("right path")
      temp.append(basic[3].text.strip()[:5]) #fuel consumption
      temp.append(basic[2].text)           #drive mode
      temp.append(basic[4].text)                #fuel type
    else:
      temp.append('')
      temp.append('')
      temp.append('')
    history = info[2].findAll("dd")
    if len(history) == 3:
      temp.append(history[0].text)
      temp.append('')
      temp.append(history[1].text)
      temp.append(history[2].text)
      temp.append('')
    elif len(history) == 4:
      if len(history[3].text)>3:
        temp.append(history[0].text)
        temp.append('')
        temp.append(history[1].text)
        temp.append(history[2].text)
        temp.append(history[3].text)
      else:
        temp.append(history[0].text)
        temp.append(history[1].text)
        temp.append(history[2].text)
        temp.append(history[3].text)
        temp.append('')
    elif len(history) == 5:
      temp.append(history[0].text)
      temp.append(history[1].text)
      temp.append(history[2].text)
      temp.append(history[3].text)
      temp.append(history[4].text)
  elif len(info) == 2:
    fir = info[0].find("dt")
    sec = info[1].find("dt")
    if fir == "Exterior color" and sec == "Convenience":
      basic = info[0].findAll("dd")
      if len(basic) == 10:
        mpg = basic[3].text.strip()[:5] #fuel consumption
        drive = basic[2].text           #drive mode
        fuel = basic[4]                 #fuel type
      else:
        temp.append('')
        temp.append('')
        temp.append('')
      temp.append('')
      temp.append('')
      temp.append('')
      temp.append('')
      temp.append('')
  li.append(temp)
def get_update(id, li):
  temp = []
  url = ('https://www.cars.com/vehicledetail/'+str(id))
  req = Request(url)
  webpage_top_50 = urlopen(req)
  page_soup = soup(webpage_top_50, "lxml")
  price = page_soup.find("span",{"class":"primary-price"})
  if price != None:
    temp.append(price.text)         #price
  else:
    temp.append('')
  temp.append(id)
  li.append(temp)

#mpg = basic[3].text.strip()[:5]
#print(basic[4].text)
#for i in basic:
  #print(i.text)
#print(mpg)
data = []
test = []

with open('cleaned_second_id.txt', 'r') as f:
    # using csv.writer method from CSV package
  for line in f:
    data.append(line[:-1])

import csv
update = []
with open('update.csv', mode ='r')as file:
  csvFile = csv.reader(file)
  for lines in csvFile:
    update.append(lines[1])

update.pop(0)

detail = []#start 0 of new5

for i in range(35000, len(data)):
  get_detail(data[i],detail)
  print(i)
#start 35000

"https://ciclt.net/sn/clt/capitolimpact/gw_ziplist.aspx?zip=030&stfips=33&state=nh&stname=New%20Hampshire"
"https://www.ciclt.net/sn/clt/capitolimpact/gw_ziplist.aspx?zip=049&stfips=23&state=me&stname=Maine"
"https://ciclt.net/sn/clt/capitolimpact/gw_ziplist.aspx?zip=050&stfips=50&state=vt&stname=Vermont"
"https://ciclt.net/sn/clt/capitolimpact/gw_ziplist.aspx?zip=262&stfips=54&state=wv&stname=West%20Virginia"
"https://www.ciclt.net/sn/clt/capitolimpact/gw_ziplist.aspx?zip=430"

import csv
fields = ['new/used','name','milage','price','id','drive mode','fuel consumption','fuel type','accident history','clean title','one owner?','personal use','factory recall']
with open("second_set(35000-).csv", 'w') as csvfile:
    csvwriter = csv.writer(csvfile)
    csvwriter.writerow(fields)
    for i in detail:
      csvwriter.writerow(i)

id = 12
temp = []
url = ('https://www.cars.com/vehicledetail/15a3e6c7-bd90-42be-9ab9-b60d17b3468c/')
req = Request(url)
webpage_top_50 = urlopen(req)
page_soup = soup(webpage_top_50, "lxml")
new_used = page_soup.find("p",{"class":"new-used"})
if new_used != None:
  temp.append(new_used.text)      #new/used
else:
  temp.append(None)
title = page_soup.find("h1",{"class":"listing-title"})
if title != None:
  temp.append(title.text)         #name(title)
else:
  temp.append(None)
#print(title.text)
mile = page_soup.find("div",{"class":"listing-mileage"})
if mile != None:
  temp.append(mile.text)          #mileage
else:
  temp.append(None)
#print(mile.text)
price = page_soup.find("span",{"class":"primary-price"})
if price != None:
  temp.append(price.text)         #price
else:
  temp.append(None)
temp.append(id)
#print(price.text)
info = page_soup.findAll("dl",{"class":"fancy-description-list"})
if len(info) == 3 or 4:
  basic = info[0].findAll("dd")
  print("basic formed")
  if len(basic) == 10:
    print("right path")
    temp.append(basic[3].text.strip()[:5]) #fuel consumption
    temp.append(basic[2].text)           #drive mode
    temp.append(basic[4].text)                #fuel type
  else:
    temp.append('')
    temp.append('')
    temp.append('')
history = info[2].findAll("dd")
if len(history) == 3:
  temp.append(history[0].text)
  temp.append('')
  temp.append(history[1].text)
  temp.append(history[2].text)
  temp.append('')
elif len(history) == 4:
  if len(history[3].text)>3:
    temp.append(history[0].text)
    temp.append('')
    temp.append(history[1].text)
    temp.append(history[2].text)
    temp.append(history[3].text)
  else:
    temp.append(history[0].text)
    temp.append(history[1].text)
    temp.append(history[2].text)
    temp.append(history[3].text)
    temp.append('')
elif len(history) == 5:
  temp.append(history[0].text)
  temp.append(history[1].text)
  temp.append(history[2].text)
  temp.append(history[3].text)
  temp.append(history[4].text)
elif len(info) == 2:
  fir = info[0].find("dt")
  sec = info[1].find("dt")
  if fir == "Exterior color" and sec == "Convenience":
    basic = info[0].findAll("dd")
    if len(basic) == 10:
      mpg = basic[3].text.strip()[:5] #fuel consumption
      drive = basic[2].text           #drive mode
      fuel = basic[4]                 #fuel type
    else:
      temp.append('')
      temp.append('')
      temp.append('')
  temp.append('')
  temp.append('')
  temp.append('')
  temp.append('')
  temp.append('')